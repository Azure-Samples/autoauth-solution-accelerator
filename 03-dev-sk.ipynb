{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory changed to C:\\Users\\pablosal\\Desktop\\gbb-ai-hls-factory-prior-auth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the target directory\n",
    "target_directory = r\"C:\\Users\\pablosal\\Desktop\\gbb-ai-hls-factory-prior-auth\"  # change your directory here\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(target_directory):\n",
    "    # Change the current working directory\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"Directory {target_directory} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade semantic_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import (\n",
    "    AzureChatPromptExecutionSettings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.17.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_ID = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_ID\")\n",
    "\n",
    "service_id = \"gpt-4o\"\n",
    "# Add Azure OpenAI chat completion\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    service_id=service_id,\n",
    "    deployment_name=AZURE_OPENAI_CHAT_DEPLOYMENT_ID,\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to create function from directory: C:\\Users\\pablosal\\Desktop\\gbb-ai-hls-factory-prior-auth\\src\\agenticai\\plugins\\plugins_store\\hello_world\\plugins_store\n",
      "Failed to create function from directory: C:\\Users\\pablosal\\Desktop\\gbb-ai-hls-factory-prior-auth\\src\\agenticai\\plugins\\plugins_store\\hello_world\\prompt\n"
     ]
    }
   ],
   "source": [
    "# # Define the parent directory and plugin name\n",
    "# parent_directory = os.path.abspath(\"src\\\\agenticai\\\\plugins\")\n",
    "# plugin_name = \"prompt\"\n",
    "\n",
    "# # Add the plugin to the kernel\n",
    "# plugin = kernel.add_plugin(parent_directory=parent_directory, plugin_name=plugin_name)\n",
    "\n",
    "# Define the parent directory and plugin name\n",
    "# parent_directory = os.path.abspath(\"src\\\\agenticai\\\\plugins\\\\plugins_store\")\n",
    "# plugin_name = \"retrieval\"\n",
    "\n",
    "# # Add the plugin to the kernel\n",
    "# kernel.add_plugin(parent_directory=parent_directory, plugin_name=plugin_name)\n",
    "\n",
    "# # Define the parent directory and plugin name\n",
    "parent_directory = os.path.abspath(\"src\\\\agenticai\\\\plugins\\\\plugins_store\\\\\")\n",
    "plugin_name = \"hello_world\"\n",
    "\n",
    "# Add the plugin to the kernel\n",
    "plugin = kernel.add_plugin(parent_directory=parent_directory, plugin_name=plugin_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello_world': KernelPlugin(name='hello_world', description=None, functions={'limerick': KernelFunctionFromPrompt(metadata=KernelFunctionMetadata(name='limerick', plugin_name='hello_world', description='Generate a funny limerick about a person', parameters=[KernelParameterMetadata(name='name', description='', default_value='Bob', type_='', is_required=True, type_object=None, schema_data={'type': 'object', 'description': '(default value: Bob)'}, include_in_function_choices=True), KernelParameterMetadata(name='input', description='', default_value='Dogs', type_='', is_required=True, type_object=None, schema_data={'type': 'object', 'description': '(default value: Dogs)'}, include_in_function_choices=True)], is_prompt=True, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='The completion result', default_value=None, type_='FunctionResult', is_required=True, type_object=None, schema_data=None, include_in_function_choices=True), additional_properties=None), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x0000012546257070>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x0000012546256A70>, prompt_template=KernelPromptTemplate(prompt_template_config=PromptTemplateConfig(name='limerick', description='Generate a funny limerick about a person', template=\"There was a young woman named Bright,\\nWhose speed was much faster than light.\\nShe set out one day,\\nIn a relative way,\\nAnd returned on the previous night.\\n\\nThere was an odd fellow named Gus,\\nWhen traveling he made such a fuss.\\nHe was banned from the train,\\nNot allowed on a plane,\\nAnd now travels only by bus.\\n\\nThere once was a man from Tibet,\\nWho couldn't find a cigarette\\nSo he smoked all his socks,\\nand got chicken-pox,\\nand had to go to the vet.\\n\\nThere once was a boy named Dan,\\nwho wanted to fry in a pan.\\nHe tried and he tried,\\nand eventually died,\\nthat weird little boy named Dan.\\n\\nNow write a very funny limerick about {{$name}}.\\n{{$input}}\\nInvent new facts their life. Must be funny.\", template_format='semantic-kernel', input_variables=[InputVariable(name='name', description='', default='Bob', is_required=True, json_schema='', allow_dangerously_set_content=False), InputVariable(name='input', description='', default='Dogs', is_required=True, json_schema='', allow_dangerously_set_content=False)], allow_dangerously_set_content=False, execution_settings={'default': PromptExecutionSettings(service_id=None, extension_data={'max_tokens': 100, 'temperature': 0.7, 'top_p': 0.1, 'presence_penalty': 0.1, 'frequency_penalty': 0.1}, function_choice_behavior=None)}), allow_dangerously_set_content=False), prompt_execution_settings={'default': PromptExecutionSettings(service_id=None, extension_data={'max_tokens': 100, 'temperature': 0.7, 'top_p': 0.1, 'presence_penalty': 0.1, 'frequency_penalty': 0.1}, function_choice_behavior=None)})})}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = KernelArguments(topic=\"time travel to dinosaur age\", length=\"super silly\")\n",
    "result = await kernel.invoke(plugin['GenerateStory'], arguments)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion : AzureChatCompletion = kernel.get_service(type=ChatCompletionClientBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_settings = AzureChatPromptExecutionSettings()\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = KernelArguments(search_text=\"the Prior authorization for Adalimumab for Crohn's Disease and Anemia due to blood loss. Related terms: Crohn's Disease, regional enteritis, inflammatory bowel disease, IBD, chronic enteritis, ileitis, anemia secondary to blood loss, iron deficiency anemia, hemorrhagic anemia. Medication: Adalimumab, Humira, anti-TNF therapy, biologic therapy, TNF inhibitor. Dosage: 160 mg initial dose (four 40 mg injections), 80 mg two weeks later (two 40 mg injections), 40 mg every other week. Duration: 6 months. Rationale: Initiation of biologic therapy due to severity of symptoms despite current treatment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 09:15:16,648 - AIQueryClassificationPlugin - MainProcess - INFO     Classifying query: Prior authorization for Adalimumab for Crohn's Disease and Anemia due to blood loss. Related terms: Crohn's Disease, regional enteritis, inflammatory bowel disease (IBD), chronic enteritis, ileitis, anemia secondary to blood loss, iron deficiency anemia, hemorrhagic anemia. Medication: Adalimumab, Humira, anti-TNF therapy, biologic therapy, TNF inhibitor. Dosage: 160 mg initial dose (four 40 mg injections), 80 mg two weeks later (two 40 mg injections), 40 mg every other week. Duration: 6 months. Rationale: Initiation of biologic therapy due to the severity of symptoms despite current treatment. (aisearchclassification.py:classify_query:109)\n",
      "[2024-12-16 09:15:16 - AIQueryClassificationPlugin:109 - INFO] Classifying query: Prior authorization for Adalimumab for Crohn's Disease and Anemia due to blood loss. Related terms: Crohn's Disease, regional enteritis, inflammatory bowel disease (IBD), chronic enteritis, ileitis, anemia secondary to blood loss, iron deficiency anemia, hemorrhagic anemia. Medication: Adalimumab, Humira, anti-TNF therapy, biologic therapy, TNF inhibitor. Dosage: 160 mg initial dose (four 40 mg injections), 80 mg two weeks later (two 40 mg injections), 40 mg every other week. Duration: 6 months. Rationale: Initiation of biologic therapy due to the severity of symptoms despite current treatment.\n",
      "2024-12-16 09:15:16,651 - micro - MainProcess - INFO     Function generate_chat_response started at 2024-12-16 09:15:16 (aoai_helper.py:generate_chat_response:370)\n",
      "[2024-12-16 09:15:16 - micro:370 - INFO] Function generate_chat_response started at 2024-12-16 09:15:16\n",
      "2024-12-16 09:15:16,654 - micro - MainProcess - INFO     Sending request to Azure OpenAI at 2024-12-16 09:15:16 (aoai_helper.py:generate_chat_response:427)\n",
      "[2024-12-16 09:15:16 - micro:427 - INFO] Sending request to Azure OpenAI at 2024-12-16 09:15:16\n",
      "2024-12-16 09:15:22,161 - micro - MainProcess - INFO     Function generate_chat_response finished at 2024-12-16 09:15:22 (Duration: 5.51 seconds) (aoai_helper.py:generate_chat_response:481)\n",
      "[2024-12-16 09:15:22 - micro:481 - INFO] Function generate_chat_response finished at 2024-12-16 09:15:22 (Duration: 5.51 seconds)\n",
      "2024-12-16 09:15:22,164 - AIQueryClassificationPlugin - MainProcess - INFO     Query classified as: semantic (aisearchclassification.py:classify_query:122)\n",
      "[2024-12-16 09:15:22 - AIQueryClassificationPlugin:122 - INFO] Query classified as: semantic\n",
      "2024-12-16 09:15:22,165 - AIQueryClassificationPlugin - MainProcess - INFO     Query classified as: semantic (aisearchclassification.py:classify_query:128)\n",
      "[2024-12-16 09:15:22 - AIQueryClassificationPlugin:128 - INFO] Query classified as: semantic\n",
      "2024-12-16 09:15:32,882 - AgenticRAG - Plugin AzureSearchPlugin - MainProcess - INFO     Function semantic_search called. (aisearch.py:semantic_search:156)\n",
      "[2024-12-16 09:15:32 - AgenticRAG - Plugin AzureSearchPlugin:156 - INFO] Function semantic_search called.\n",
      "2024-12-16 09:15:32,884 - AgenticRAG - Plugin AzureSearchPlugin - MainProcess - ERROR    semantic_search - Error during semantic search: 'AzureSearchPlugin' object is not iterable (aisearch.py:semantic_search:175)\n",
      "[2024-12-16 09:15:32 - AgenticRAG - Plugin AzureSearchPlugin:175 - ERROR] semantic_search - Error during semantic search: 'AzureSearchPlugin' object is not iterable\n",
      "2024-12-16 09:15:32,887 - AgenticRAG - Plugin AzureSearchPlugin - MainProcess - INFO     Function keyword_search called. (aisearch.py:keyword_search:74)\n",
      "[2024-12-16 09:15:32 - AgenticRAG - Plugin AzureSearchPlugin:74 - INFO] Function keyword_search called.\n",
      "2024-12-16 09:15:33,149 - AgenticRAG - Plugin AzureSearchPlugin - MainProcess - INFO     Function hybrid_search called. (aisearch.py:hybrid_search:195)\n",
      "[2024-12-16 09:15:33 - AgenticRAG - Plugin AzureSearchPlugin:195 - INFO] Function hybrid_search called.\n",
      "2024-12-16 09:15:33,154 - AgenticRAG - Plugin AzureSearchPlugin - MainProcess - ERROR    hybrid_search - Error during hybrid search: 'AzureSearchPlugin' object has no attribute '_extract_search_results' (aisearch.py:hybrid_search:210)\n",
      "[2024-12-16 09:15:33 - AgenticRAG - Plugin AzureSearchPlugin:210 - ERROR] hybrid_search - Error during hybrid search: 'AzureSearchPlugin' object has no attribute '_extract_search_results'\n"
     ]
    }
   ],
   "source": [
    "# Create a history of the conversation\n",
    "chat_history = ChatHistory()\n",
    "\n",
    "# Add system message to the chat history to define the system's role\n",
    "chat_history.add_system_message(\n",
    "    \"You are an AI-powered assistant that specializes in policy retrieval for prior authorization queries. \"\n",
    "    \"Your task is to classify the query and select the best search strategy (keyword, semantic, or hybrid). \"\n",
    "    \"Once the classification is complete, you will evaluate multiple potential policies, calculate their relevance, \"\n",
    "    \"and return a JSON object with the following details:\\n\"\n",
    "    \"1. **List of Evaluated Policies**: Each policy includes its name, relevance score, and reasoning for its relevance.\\n\"\n",
    "    \"2. **Confidence Levels**: Each policy is given a confidence score based on its alignment with the search criteria.\\n\"\n",
    "    \"3. **Final Policy Selection**: The system will select the policy with the highest confidence score as the final policy.\\n\"\n",
    "    \"4. **JSON Response**: The final response will be a JSON object with the format:\\n\"\n",
    "    \"```json\\n\"\n",
    "    \"{\\n\"\n",
    "    \"  'evaluated_policies': [\\n\"\n",
    "    \"    {\\n\"\n",
    "    \"      'policy_name': '<name>',\\n\"\n",
    "    \"      'confidence_score': <float>,\\n\"\n",
    "    \"      'reasoning': '<explanation of why this policy was selected>'\\n\"\n",
    "    \"    },\\n\"\n",
    "    \"    ...\\n\"\n",
    "    \"  ],\\n\"\n",
    "    \"  'final_selected_policy': {\\n\"\n",
    "    \"    'policy_name': '<name>',\\n\"\n",
    "    \"    'confidence_score': <float>,\\n\"\n",
    "    \"    'reasoning': '<why this policy was selected as the best option>'\\n\"\n",
    "    \"  }\\n\"\n",
    "    \"}\\n\"\n",
    ")\n",
    "\n",
    "# User message containing a detailed query\n",
    "chat_history.add_user_message(\n",
    "    \"I need the most relevant policy that matches my search criteria. \"\n",
    "    \"Please classify the query and retrieve the best-matching policy using the most effective search strategy. \"\n",
    "    \"Here is the search query: Prior authorization for Adalimumab for Crohn's Disease and Anemia due to blood loss. \"\n",
    "    \"Related terms: Crohn's Disease, regional enteritis, inflammatory bowel disease (IBD), chronic enteritis, ileitis, \"\n",
    "    \"anemia secondary to blood loss, iron deficiency anemia, hemorrhagic anemia. \"\n",
    "    \"Medication: Adalimumab, Humira, anti-TNF therapy, biologic therapy, TNF inhibitor. \"\n",
    "    \"Dosage: 160 mg initial dose (four 40 mg injections), 80 mg two weeks later (two 40 mg injections), 40 mg every other week. \"\n",
    "    \"Duration: 6 months. \"\n",
    "    \"Rationale: Initiation of biologic therapy due to the severity of symptoms despite current treatment. \"\n",
    "    \"Please evaluate this query using all available retrieval methods to determine the most effective classification and strategy. \"\n",
    "    \"Once you have the classification, use it to select one of the following retrieval strategies: **keyword**, **semantic**, or **hybrid** search.\\n\\n\"\n",
    "    \"Evaluate all the retrieved policies and calculate their confidence scores. Return a detailed JSON object as follows:\\n\"\n",
    "    \"1. **List of Evaluated Policies**: Each policy includes its name, relevance score, and reasoning for its relevance.\\n\"\n",
    "    \"2. **Confidence Levels**: Each policy is assigned a confidence score from 0 to 1.\\n\"\n",
    "    \"3. **Final Policy Selection**: The system selects the policy with the highest confidence score.\\n\"\n",
    "    \"4. **Return the JSON Object**: The response should be a JSON object with the following structure:\\n\"\n",
    "    \"```json\\n\"\n",
    "    \"{\\n\"\n",
    "    \"  'evaluated_policies': [\\n\"\n",
    "    \"    {\\n\"\n",
    "    \"      'policy_name': '<name>',\\n\"\n",
    "    \"      'confidence_score': <float>,\\n\"\n",
    "    \"      'reasoning': '<explanation of why this policy was selected>'\\n\"\n",
    "    \"    },\\n\"\n",
    "    \"    ...\\n\"\n",
    "    \"  ],\\n\"\n",
    "    \"  'final_selected_policy': {\\n\"\n",
    "    \"    'policy_name': '<name>',\\n\"\n",
    "    \"    'confidence_score': <float>,\\n\"\n",
    "    \"    'reasoning': '<why this policy was selected as the best option>'\\n\"\n",
    "    \"  }\\n\"\n",
    "    \"}\\n\"\n",
    ")\n",
    "\n",
    "import logging\n",
    "\n",
    "# Set the logging level for  semantic_kernel.kernel to DEBUG.\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s - %(name)s:%(lineno)d - %(levelname)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "from semantic_kernel.utils.logging import setup_logging\n",
    "setup_logging()\n",
    "logging.getLogger(\"kernel\").setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "# Get the response from the AI\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    "    kernel=kernel,\n",
    "    arguments=KernelArguments(),\n",
    "))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessageContent(inner_content=ChatCompletion(id='chatcmpl-Aendd842ly7Q2blnqGeGf3SCSlufZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The most relevant policy matching your criteria is from the **Cigna National Formulary Coverage - Policy: Inflammatory Conditions - Adalimumab Products Prior Authorization**. Here are the key excerpts from the document that align with your query:\\n\\n1. **Requirement for Trials Before Starting Adalimumab**:\\n   - Patients must have a history of trying steroids or another conventional systemic agent unless they have previously tried at least one biologic other than the requested medication. \\n   - Mesalamine does not count as a systemic agent for Crohn's disease.\\n   - Patients may have enterocutaneous (perianal or abdominal) or rectovaginal fistulas.\\n\\n2. **Clinical Response Requirements**:\\n   - Beneficial clinical response is defined as improvement in at least one of the following parameters: size, depth, or number of lesions, and improvement in symptoms such as decreased pain and tenderness of affected lesions.\\n   - For conditions like Sarcoidosis, initial therapy approval is for 3 months if patients have tried at least one corticosteroid and one immunosuppressive medication.\\n\\n3. **Approvals Based on Current Therapy**:\\n   - Continued approval for 1 year if patients have been on therapy for at least 3 months and experienced a beneficial clinical response from baseline, such as lung function improvement, serum markers, symptom improvement, or imaging results.\\n\\n4. **Contraindications and Aggressive Disease**:\\n   - Patients with aggressive disease, as determined by their prescriber, and other specific contraindications such as pregnancy, breast feeding, alcoholic liver disease, immunodeficiency syndrome, and blood dyscrasias must be noted.\\n   \\n5. **Consultation with Specialists**:\\n   - All initial approvals require prescription by or consultation with a specialist in the condition being treated, ensuring ongoing monitoring and specialized skills for evaluating and diagnosing patients.\\n\\n6. **Place on the Therapy Pathway**:\\n   - Adalimumab can be considered after trials of other therapies have failed, been contraindicated, or deemed insufficient in managing the patients' symptoms.\\n\\nFor a comprehensive review, here is the relevant document you can refer to further: [Cigna National Formulary Coverage - Policy: Inflammatory Conditions - Adalimumab Products Prior Authorization](https://storageaeastusfactory.blob.core.windows.net/pre-auth-policies/policies_ocr/001.pdf).\\n\\nThis document provides detailed criteria and conditions for the prior authorization of Adalimumab, which closely aligns with the details provided in your query.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1734287293, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_84ac7e2412', usage=CompletionUsage(completion_tokens=507, prompt_tokens=7247, total_tokens=7754, completion_tokens_details=None, prompt_tokens_details=None)), ai_model_id='gpt-4o-standard', metadata={'logprobs': None, 'id': 'chatcmpl-Aendd842ly7Q2blnqGeGf3SCSlufZ', 'created': 1734287293, 'system_fingerprint': 'fp_84ac7e2412', 'usage': CompletionUsage(prompt_tokens=7247, completion_tokens=507)}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=\"The most relevant policy matching your criteria is from the **Cigna National Formulary Coverage - Policy: Inflammatory Conditions - Adalimumab Products Prior Authorization**. Here are the key excerpts from the document that align with your query:\\n\\n1. **Requirement for Trials Before Starting Adalimumab**:\\n   - Patients must have a history of trying steroids or another conventional systemic agent unless they have previously tried at least one biologic other than the requested medication. \\n   - Mesalamine does not count as a systemic agent for Crohn's disease.\\n   - Patients may have enterocutaneous (perianal or abdominal) or rectovaginal fistulas.\\n\\n2. **Clinical Response Requirements**:\\n   - Beneficial clinical response is defined as improvement in at least one of the following parameters: size, depth, or number of lesions, and improvement in symptoms such as decreased pain and tenderness of affected lesions.\\n   - For conditions like Sarcoidosis, initial therapy approval is for 3 months if patients have tried at least one corticosteroid and one immunosuppressive medication.\\n\\n3. **Approvals Based on Current Therapy**:\\n   - Continued approval for 1 year if patients have been on therapy for at least 3 months and experienced a beneficial clinical response from baseline, such as lung function improvement, serum markers, symptom improvement, or imaging results.\\n\\n4. **Contraindications and Aggressive Disease**:\\n   - Patients with aggressive disease, as determined by their prescriber, and other specific contraindications such as pregnancy, breast feeding, alcoholic liver disease, immunodeficiency syndrome, and blood dyscrasias must be noted.\\n   \\n5. **Consultation with Specialists**:\\n   - All initial approvals require prescription by or consultation with a specialist in the condition being treated, ensuring ongoing monitoring and specialized skills for evaluating and diagnosing patients.\\n\\n6. **Place on the Therapy Pathway**:\\n   - Adalimumab can be considered after trials of other therapies have failed, been contraindicated, or deemed insufficient in managing the patients' symptoms.\\n\\nFor a comprehensive review, here is the relevant document you can refer to further: [Cigna National Formulary Coverage - Policy: Inflammatory Conditions - Adalimumab Products Prior Authorization](https://storageaeastusfactory.blob.core.windows.net/pre-auth-policies/policies_ocr/001.pdf).\\n\\nThis document provides detailed criteria and conditions for the prior authorization of Adalimumab, which closely aligns with the details provided in your query.\", encoding=None)], encoding=None, finish_reason=<FinishReason.STOP: 'stop'>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the hybrid search results, the system evaluated the relevant policies and calculated their confidence scores. Here is the detailed response:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"evaluated_policies\": [\n",
      "    {\n",
      "      \"policy_name\": \"001.pdf - Page 5\",\n",
      "      \"confidence_score\": 0.85,\n",
      "      \"reasoning\": \"The policy specifically mentions requirements for Crohn's Disease, use of corticosteroids, and alternative systemic therapies. The duration for initial therapy is also specified as 6 months, which aligns well with the query.\"\n",
      "    },\n",
      "    {\n",
      "      \"policy_name\": \"001.pdf - Page 6\",\n",
      "      \"confidence_score\": 0.80,\n",
      "      \"reasoning\": \"The policy discusses approval criteria for patients currently receiving Adalimumab, including Crohn's Disease and related requirements. This includes ongoing therapy for at least 6 months.\"\n",
      "    },\n",
      "    {\n",
      "      \"policy_name\": \"001.pdf - Page 10\",\n",
      "      \"confidence_score\": 0.75,\n",
      "      \"reasoning\": \"This policy section mentions therapy conditions for patients with Crohn's Disease, including the role of a gastroenterologist and beneficial clinical responses.\"\n",
      "    },\n",
      "    {\n",
      "      \"policy_name\": \"001.pdf - Page 1\",\n",
      "      \"confidence_score\": 0.70,\n",
      "      \"reasoning\": \"Provides general guidelines for Adalimumab for multiple indications including Crohn's Disease. However, it's not as specific as other documents.\"\n",
      "    },\n",
      "    {\n",
      "      \"policy_name\": \"001.pdf - Page 4\",\n",
      "      \"confidence_score\": 0.65,\n",
      "      \"reasoning\": \"Mentions a range of Adalimumab products and general usage criteria, including inflammatory conditions. Highly relevant but less specific.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_selected_policy\": {\n",
      "    \"policy_name\": \"001.pdf - Page 5\",\n",
      "    \"confidence_score\": 0.85,\n",
      "    \"reasoning\": \"This policy is the most specific, covering the essential requirements for initial therapy, the use of corticosteroids or systemic therapies, and the alignment with the 6-month duration specified in the query.\"\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "This JSON object includes a list of evaluated policies with their respective confidence scores and the reasoning behind their scores. The final selected policy has the highest confidence score and best matches the search query criteria.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.functions import kernel_function\n",
    "import asyncio\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Step 1: Define Agent Configuration and Agent Classes\n",
    "class AgentConfig:\n",
    "    \"\"\"Configuration for an Agent.\"\"\"\n",
    "    def __init__(self, name: str, role: str, skills: List[str]):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.skills = skills\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"Class for an Agent that can interact with the Semantic Kernel.\"\"\"\n",
    "    def __init__(self, config: AgentConfig, kernel: sk.Kernel):\n",
    "        self.name = config.name\n",
    "        self.role = config.role\n",
    "        self.skills = config.skills\n",
    "        self.kernel = kernel\n",
    "        self.context = {}  # Dictionary to store context variables\n",
    "\n",
    "    def register_skills(self):\n",
    "        \"\"\"Load all skills for the agent.\"\"\"\n",
    "        for skill_name in self.skills:\n",
    "            self.kernel.import_skill(skill_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'semantic_kernel.orchestration'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msemantic_kernel\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msk\u001b[39;00m \n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msemantic_kernel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morchestration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ContextVariables \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the kernel \u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'semantic_kernel.orchestration'"
     ]
    }
   ],
   "source": [
    "class Skills:\n",
    "    @kernel_function\n",
    "    def search_skill(self, query: str, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Search Skill: Queries Azure AI Search to retrieve relevant content.\"\"\"\n",
    "        # Placeholder logic for search\n",
    "        print(f\"Executing search skill with query: {query}\")\n",
    "        return {\"content\": f\"Results for {query}\"}\n",
    "\n",
    "    @kernel_function\n",
    "    def validation_skill(self, document_content: str, reference_content: str) -> bool:\n",
    "        \"\"\"Validation Skill: Validates retrieved content against a reference document.\"\"\"\n",
    "        print(\"Validating document content against reference content.\")\n",
    "        return document_content in reference_content  # Simple validation logic\n",
    "\n",
    "    @kernel_function\n",
    "    def query_rewrite_skill(self, original_query: str, feedback: str) -> str:\n",
    "        \"\"\"Query Rewrite Skill: Modifies the query based on feedback from validation.\"\"\"\n",
    "        print(\"Rewriting query based on feedback.\")\n",
    "        return f\"{original_query} {feedback}\"  # Simple concatenation for demonstration purposes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Document Retrieval Agent\n",
    "retrieval_agent_config = AgentConfig(\n",
    "    name=\"DocumentRetrievalAgent\",\n",
    "    role=\"Retrieve relevant documents from Azure AI Search\",\n",
    "    skills=[\"search_skill\"]\n",
    ")\n",
    "retrieval_agent = Agent(config=retrieval_agent_config, kernel=kernel)\n",
    "retrieval_agent.register_skills()\n",
    "\n",
    "# Agent 2: Validation Agent\n",
    "validation_agent_config = AgentConfig(\n",
    "    name=\"DocumentValidationAgent\",\n",
    "    role=\"Check document accuracy against original content\",\n",
    "    skills=[\"validation_skill\"]\n",
    ")\n",
    "validation_agent = Agent(config=validation_agent_config, kernel=kernel)\n",
    "validation_agent.register_skills()\n",
    "\n",
    "# Agent 3: Query Rewrite Agent\n",
    "query_rewrite_agent_config = AgentConfig(\n",
    "    name=\"QueryRewriteAgent\",\n",
    "    role=\"Rewrite search query based on feedback\",\n",
    "    skills=[\"query_rewrite_skill\"]\n",
    ")\n",
    "query_rewrite_agent = Agent(config=query_rewrite_agent_config, kernel=kernel)\n",
    "query_rewrite_agent.register_skills()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.agents import AgentGroupChat, ChatCompletionAgent\n",
    "from semantic_kernel.agents.strategies import (\n",
    "    KernelFunctionSelectionStrategy,\n",
    "    KernelFunctionTerminationStrategy,\n",
    ")\n",
    "from semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion import AzureChatCompletion\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.functions.kernel_function_from_prompt import KernelFunctionFromPrompt\n",
    "from semantic_kernel.kernel import Kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mChatCompletionAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mservice_id\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mkernel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Kernel | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mid\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdescription\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minstructions\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mexecution_settings\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msemantic_kernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprompt_execution_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPromptExecutionSettings\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "A KernelAgent specialization based on ChatCompletionClientBase.\n",
      "\n",
      "    Note: enable `function_choice_behavior` on the PromptExecutionSettings to enable function\n",
      "    choice behavior which allows the kernel to utilize plugins and functions registered in\n",
      "    the kernel.\n",
      "    \n",
      "\n",
      "Note: This class is experimental and may change in the future.\n",
      "\u001b[1;31mInit docstring:\u001b[0m\n",
      "Initialize a new instance of ChatCompletionAgent.\n",
      "\n",
      "Args:\n",
      "    service_id: The service id for the chat completion service. (optional) If not provided,\n",
      "        the default service name `default` will be used.\n",
      "    kernel: The kernel instance. (optional)\n",
      "    name: The name of the agent. (optional)\n",
      "    id: The unique identifier for the agent. (optional) If not provided,\n",
      "        a unique GUID will be generated.\n",
      "    description: The description of the agent. (optional)\n",
      "    instructions: The instructions for the agent. (optional)\n",
      "    execution_settings: The execution settings for the agent. (optional)\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\pa-ai-env\\lib\\site-packages\\semantic_kernel\\agents\\chat_completion\\chat_completion_agent.py\n",
      "\u001b[1;31mType:\u001b[0m           ModelMetaclass\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "ChatCompletionAgent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='C:\\\\Users\\\\pablosal\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\pa-ai-env\\\\Library\\\\ssl\\\\cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='C:\\\\Users\\\\pablosal\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\pa-ai-env\\\\Library\\\\ssl\\\\cacert.pem'\n",
      "DEBUG:semantic_kernel.functions.kernel_plugin:Found object: C:\\Users\\pablosal\\Desktop\\gbb-ai-hls-factory-prior-auth\\src\\agenticai\\plugins\\plugins_store\\retrieval\\aisearch.py\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing decorator for function: keyword_search\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: search_text\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: top\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'int'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:annotations=[{'name': 'search_text', 'is_required': True, 'type_': 'str', 'type_object': <class 'str'>}, {'name': 'top', 'default_value': 5, 'is_required': False, 'type_': 'int', 'type_object': <class 'int'>}]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Annotated[typing.List[typing.Dict[str, typing.Any]], 'A list of search results for the keyword query']\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.List[typing.Dict[str, typing.Any]]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'list'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Dict[str, typing.Any]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'dict'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Any\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.List[typing.Dict[str, typing.Any]]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'list'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Dict[str, typing.Any]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'dict'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Any\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing decorator for function: semantic_search\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: search_text\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: top\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'int'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:annotations=[{'name': 'search_text', 'is_required': True, 'type_': 'str', 'type_object': <class 'str'>}, {'name': 'top', 'default_value': 5, 'is_required': False, 'type_': 'int', 'type_object': <class 'int'>}]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Annotated[typing.List[typing.Dict[str, typing.Any]], 'A list of search results for the semantic query']\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.List[typing.Dict[str, typing.Any]]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'list'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Dict[str, typing.Any]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'dict'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Any\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.List[typing.Dict[str, typing.Any]]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'list'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Dict[str, typing.Any]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'dict'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Any\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing decorator for function: hybrid_search\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: search_text\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: top\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'int'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:annotations=[{'name': 'search_text', 'is_required': True, 'type_': 'str', 'type_object': <class 'str'>}, {'name': 'top', 'default_value': 5, 'is_required': False, 'type_': 'int', 'type_object': <class 'int'>}]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Annotated[typing.List[typing.Dict[str, typing.Any]], 'A list of search results for the hybrid query']\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.List[typing.Dict[str, typing.Any]]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'list'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Dict[str, typing.Any]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'dict'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Any\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.List[typing.Dict[str, typing.Any]]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'list'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Dict[str, typing.Any]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'dict'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Any\n",
      "2024-12-15 22:10:49,905 - AgenticRAG - Plugin AzureSearchPlugin - MainProcess - INFO     Initializing SearchClient with endpoint: https://search-ai-factory-centralus.search.windows.net, index_name: ai-policies-index (aisearch.py:__init__:49)\n",
      "INFO:AgenticRAG - Plugin AzureSearchPlugin:Initializing SearchClient with endpoint: https://search-ai-factory-centralus.search.windows.net, index_name: ai-policies-index\n",
      "2024-12-15 22:10:49,909 - AgenticRAG - Plugin AzureSearchPlugin - MainProcess - INFO     SearchClient initialized successfully. (aisearch.py:__init__:52)\n",
      "INFO:AgenticRAG - Plugin AzureSearchPlugin:SearchClient initialized successfully.\n",
      "DEBUG:semantic_kernel.functions.kernel_plugin:Found object: C:\\Users\\pablosal\\Desktop\\gbb-ai-hls-factory-prior-auth\\src\\agenticai\\plugins\\plugins_store\\retrieval\\aisearchclassification.py\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing decorator for function: classify_search_query\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: query_text\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Annotated[str, \"The user's search query to be classified.\"]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: query_text\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: query_text\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:annotations=[{'name': 'query_text', 'is_required': True, 'description': \"The user's search query to be classified.\", 'type_': 'str', 'type_object': <class 'str'>}]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: typing.Annotated[str, \"The classification for the query as 'keyword', 'semantic', or 'hybrid'.\"]\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing param: return\n",
      "DEBUG:semantic_kernel.functions.kernel_function_decorator:Parsing annotation: <class 'str'>\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='C:\\\\Users\\\\pablosal\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\pa-ai-env\\\\Library\\\\ssl\\\\cacert.pem'\n",
      "2024-12-15 22:10:50,337 - AIQueryClassificationPlugin - MainProcess - INFO     OpenAI client initialized successfully. (aisearchclassification.py:__init__:100)\n",
      "INFO:AIQueryClassificationPlugin:OpenAI client initialized successfully.\n",
      "DEBUG:semantic_kernel.functions.kernel_plugin:Found object: C:\\Users\\pablosal\\Desktop\\gbb-ai-hls-factory-prior-auth\\src\\agenticai\\plugins\\plugins_store\\retrieval\\__init__.py\n",
      "WARNING:semantic_kernel.functions.kernel_plugin:Failed to create function from Python file: C:\\Users\\pablosal\\Desktop\\gbb-ai-hls-factory-prior-auth\\src\\agenticai\\plugins\\plugins_store\\retrieval\\__init__.py\n",
      "DEBUG:semantic_kernel.functions.kernel_plugin:Found object: C:\\Users\\pablosal\\Desktop\\gbb-ai-hls-factory-prior-auth\\src\\agenticai\\plugins\\plugins_store\\retrieval\\__pycache__\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='C:\\\\Users\\\\pablosal\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\pa-ai-env\\\\Library\\\\ssl\\\\cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='C:\\\\Users\\\\pablosal\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\pa-ai-env\\\\Library\\\\ssl\\\\cacert.pem'\n",
      "DEBUG:semantic_kernel.prompt_template.kernel_prompt_template:Extracting blocks from template: \n",
      "    Determine if the content evaluation has been approved. If so, respond 'yes.'\n",
      "    If not, state 'no.'\n",
      "\n",
      "    History:\n",
      "    {{$history}}\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "\n",
    "# NOTE: This is all that is required to enable logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "FORMULATOR_NAME = \"Formulator\"\n",
    "FORMULATOR_INSTRUCTIONS = \"\"\"\n",
    "You are responsible for formulating the query based on the given clinical metadata.\n",
    "Your job is to analyze the metadata, identify key details, and create an optimized search query.\n",
    "Output only the query string with no additional text.\n",
    "\"\"\"\n",
    "\n",
    "# Agent Instructions\n",
    "RETRIEVER_NAME = \"Retriever\"\n",
    "RETRIEVER_INSTRUCTIONS = \"\"\"\n",
    "You are responsible for retrieving content from Azure AI Search.\n",
    "Use the provided query to search the database and return the top document results.\n",
    "Please make sure to determine the retrieval strategy based on the query. Classify the query first and then retrieve the information.\n",
    "If there are no results, state 'No relevant content found.'\n",
    "\"\"\"\n",
    "\n",
    "# Agent Instructions\n",
    "EVALUATOR_NAME = \"Evaluator\"\n",
    "EVALUATOR_INSTRUCTIONS = \"\"\"\n",
    "You are responsible for evaluating if the retrieved content is accurate and matches the original clinical requirements.\n",
    "If the content is acceptable, respond 'Approved.'\n",
    "If the content is not accurate or does not solve the issue, suggest improvements without examples.\n",
    "\"\"\"\n",
    "\n",
    "def _create_kernel_with_chat_completion(service_id: str) -> Kernel:\n",
    "    kernel = Kernel()\n",
    "    AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "    AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "    AZURE_OPENAI_EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "    AZURE_OPENAI_CHAT_DEPLOYMENT_ID = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_ID\")\n",
    "\n",
    "    service_id=service_id\n",
    "    # Add Azure OpenAI chat completion\n",
    "    kernel.add_service(AzureChatCompletion(\n",
    "        service_id=service_id,\n",
    "        deployment_name=AZURE_OPENAI_CHAT_DEPLOYMENT_ID,\n",
    "        api_key=AZURE_OPENAI_KEY,\n",
    "        endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_version=AZURE_OPENAI_API_VERSION,\n",
    "    ))\n",
    "    return kernel\n",
    "\n",
    "\n",
    "agent_formulator = ChatCompletionAgent(\n",
    "    service_id=FORMULATOR_NAME,\n",
    "    kernel=_create_kernel_with_chat_completion(FORMULATOR_NAME),\n",
    "    name=FORMULATOR_NAME,\n",
    "    instructions=FORMULATOR_INSTRUCTIONS,\n",
    ")\n",
    "\n",
    "kernel_retriever = Kernel()\n",
    "kernel_retriever.add_service(AzureChatCompletion(\n",
    "    service_id=RETRIEVER_NAME,\n",
    "    deployment_name=AZURE_OPENAI_CHAT_DEPLOYMENT_ID,\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "))\n",
    "parent_directory = os.path.abspath(\"src\\\\agenticai\\\\plugins\\\\plugins_store\")\n",
    "\n",
    "plugin_name = \"retrieval\"\n",
    "\n",
    "# Add the plugin to the kernel\n",
    "kernel.add_plugin(parent_directory=parent_directory, plugin_name=plugin_name)\n",
    "\n",
    "agent_retriever = ChatCompletionAgent(\n",
    "    service_id=RETRIEVER_NAME,\n",
    "    kernel=_create_kernel_with_chat_completion(RETRIEVER_NAME),\n",
    "    name=RETRIEVER_NAME,\n",
    "    instructions=RETRIEVER_INSTRUCTIONS,\n",
    ")\n",
    "\n",
    "agent_evaluator = ChatCompletionAgent(\n",
    "    service_id=EVALUATOR_NAME,\n",
    "    kernel=_create_kernel_with_chat_completion(EVALUATOR_NAME),\n",
    "    name=EVALUATOR_NAME,\n",
    "    instructions=EVALUATOR_INSTRUCTIONS,\n",
    ")\n",
    "\n",
    "\n",
    "termination_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"termination\",\n",
    "    prompt=\"\"\"\n",
    "    Determine if the content evaluation has been approved. If so, respond 'yes.'\n",
    "    If not, state 'no.'\n",
    "\n",
    "    History:\n",
    "    {{$history}}\n",
    "    \"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:semantic_kernel.prompt_template.kernel_prompt_template:Extracting blocks from template: \n",
      "    Determine which participant takes the next turn in a conversation based on the the most recent participant.\n",
      "    State only the name of the participant to take the next turn.\n",
      "    No participant should take more than one turn in a row.\n",
      "\n",
      "    Choose only from these participants:\n",
      "        - Formulator\n",
      "        - Retriever\n",
      "        - Evaluator\n",
      "\n",
      "    Always follow these rules when selecting the next participant:\n",
      "    - Formulator starts first and formulates the query.\n",
      "    - After Formulator, it is Retriever's turn to retrieve the document.\n",
      "    - After Retriever, it is Evaluator's turn to evaluate the content.\n",
      "    - After Evaluator, the workflow may terminate if approved.\n",
      "\n",
      "    History:\n",
      "    {{$history}}\n",
      "    \n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='C:\\\\Users\\\\pablosal\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\pa-ai-env\\\\Library\\\\ssl\\\\cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='C:\\\\Users\\\\pablosal\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\pa-ai-env\\\\Library\\\\ssl\\\\cacert.pem'\n",
      "INFO:semantic_kernel.agents.group_chat.agent_chat:Adding `1` agent chat messages\n",
      "INFO:semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy:Kernel Function Selection Strategy next method called, invoking function: , selection\n",
      "INFO:semantic_kernel.functions.kernel_function:Function selection invoking.\n",
      "DEBUG:semantic_kernel.functions.kernel_function:Function arguments: {'agents': 'Formulator,Retriever,Evaluator', 'history': [{'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}]}\n",
      "DEBUG:semantic_kernel.prompt_template.kernel_prompt_template:Rendering list of 3 blocks\n",
      "DEBUG:semantic_kernel.prompt_template.kernel_prompt_template:Rendered prompt: \n",
      "    Determine which participant takes the next turn in a conversation based on the the most recent participant.\n",
      "    State only the name of the participant to take the next turn.\n",
      "    No participant should take more than one turn in a row.\n",
      "\n",
      "    Choose only from these participants:\n",
      "        - Formulator\n",
      "        - Retriever\n",
      "        - Evaluator\n",
      "\n",
      "    Always follow these rules when selecting the next participant:\n",
      "    - Formulator starts first and formulates the query.\n",
      "    - After Formulator, it is Retriever's turn to retrieve the document.\n",
      "    - After Retriever, it is Evaluator's turn to evaluate the content.\n",
      "    - After Evaluator, the workflow may terminate if approved.\n",
      "\n",
      "    History:\n",
      "    [{'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}]\n",
      "    \n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '8c8be25c9f5b411a8bdc65a84271579b'}, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Determine which participant takes the next turn in a conversation based on the the most recent participant.\\n    State only the name of the participant to take the next turn.\\n    No participant should take more than one turn in a row.\\n\\n    Choose only from these participants:\\n        - Formulator\\n        - Retriever\\n        - Evaluator\\n\\n    Always follow these rules when selecting the next participant:\\n    - Formulator starts first and formulates the query.\\n    - After Formulator, it is Retriever's turn to retrieve the document.\\n    - After Retriever, it is Evaluator's turn to evaluate the content.\\n    - After Evaluator, the workflow may terminate if approved.\\n\\n    History:\\n    [{'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}]\"}], 'model': 'gpt-4o-standard', 'stream': False}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='aoai-ai-factory-eus-dev.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000021E446A1930>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021E4355AAC0> server_hostname='aoai-ai-factory-eus-dev.openai.azure.com' timeout=5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# user: 'I need the most relevant policy that matches my search criteria. '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000021E446A1300>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'333'), (b'Content-Type', b'application/json'), (b'apim-request-id', b'0797afe8-722b-402d-99b1-e9e51ef0f776'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-remaining-requests', b'149'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'51c23019-f962-47e5-b0a3-741b6034aa3a'), (b'x-content-type-options', b'nosniff'), (b'azureml-model-session', b'd098-20241115075854'), (b'x-ms-region', b'East US'), (b'x-envoy-upstream-service-time', b'148'), (b'x-ms-client-request-id', b'0797afe8-722b-402d-99b1-e9e51ef0f776'), (b'x-ratelimit-remaining-tokens', b'149163'), (b'Date', b'Mon, 16 Dec 2024 04:14:18 GMT')])\n",
      "INFO:httpx:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"200 OK\"\n",
      "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=2, prompt_tokens=169, total_tokens=171, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "INFO:semantic_kernel.functions.kernel_function:Function selection succeeded.\n",
      "DEBUG:semantic_kernel.functions.kernel_function:Function result: Formulator\n",
      "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.555456s\n",
      "INFO:semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy:Kernel Function Selection Strategy next method completed: , selection, result: [ChatMessageContent(inner_content=ChatCompletion(id='chatcmpl-AewmoZMBxtFnF5OvRymWggMATQ0zu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Formulator', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1734322458, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_04751d0b65', usage=CompletionUsage(completion_tokens=2, prompt_tokens=169, total_tokens=171, completion_tokens_details=None, prompt_tokens_details=None)), ai_model_id='gpt-4o-standard', metadata={'logprobs': None, 'id': 'chatcmpl-AewmoZMBxtFnF5OvRymWggMATQ0zu', 'created': 1734322458, 'system_fingerprint': 'fp_04751d0b65', 'usage': CompletionUsage(prompt_tokens=169, completion_tokens=2)}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Formulator', encoding=None)], encoding=None, finish_reason=<FinishReason.STOP: 'stop'>)]\n",
      "INFO:semantic_kernel.agents.group_chat.agent_chat:Invoking agent Formulator\n",
      "DEBUG:semantic_kernel.agents.chat_completion.chat_completion_agent:[ChatCompletionAgent] Invoking AzureChatCompletion.\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '8c8be25c9f5b411a8bdc65a84271579b'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are responsible for formulating the query based on the given clinical metadata.\\nYour job is to analyze the metadata, identify key details, and create an optimized search query.\\nOutput only the query string with no additional text.\\n', 'name': 'Formulator'}, {'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}], 'model': 'gpt-4o-standard', 'stream': False}}\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='aoai-ai-factory-eus-dev.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000021E446A4280>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021E261ABC40> server_hostname='aoai-ai-factory-eus-dev.openai.azure.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000021E446A3C10>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'367'), (b'Content-Type', b'application/json'), (b'apim-request-id', b'0343e8dd-aa58-4fad-bc71-224b2637b533'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-remaining-requests', b'148'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'1ec8e4d1-c62c-4ee4-81d8-399cdc5bcf12'), (b'x-content-type-options', b'nosniff'), (b'azureml-model-session', b'd097-20241115065003'), (b'x-ms-region', b'East US'), (b'x-envoy-upstream-service-time', b'489'), (b'x-ms-client-request-id', b'0343e8dd-aa58-4fad-bc71-224b2637b533'), (b'x-ratelimit-remaining-tokens', b'148446'), (b'Date', b'Mon, 16 Dec 2024 04:14:18 GMT')])\n",
      "INFO:httpx:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"200 OK\"\n",
      "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=10, prompt_tokens=72, total_tokens=82, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "INFO:semantic_kernel.agents.chat_completion.chat_completion_agent:[ChatCompletionAgent] Invoked AzureChatCompletion with message count: 2.\n",
      "INFO:semantic_kernel.agents.strategies.termination.termination_strategy:Evaluating termination criteria for d6bc3952-f003-47ed-89da-9724312d7f85\n",
      "INFO:semantic_kernel.agents.strategies.termination.termination_strategy:Agent d6bc3952-f003-47ed-89da-9724312d7f85 is out of scope\n",
      "INFO:semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy:Kernel Function Selection Strategy next method called, invoking function: , selection\n",
      "INFO:semantic_kernel.functions.kernel_function:Function selection invoking.\n",
      "DEBUG:semantic_kernel.functions.kernel_function:Function arguments: {'agents': 'Formulator,Retriever,Evaluator', 'history': [{'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}, {'role': 'assistant', 'content': 'site:gov OR site:edu policy relevant criteria', 'name': 'Formulator'}]}\n",
      "DEBUG:semantic_kernel.prompt_template.kernel_prompt_template:Rendering list of 3 blocks\n",
      "DEBUG:semantic_kernel.prompt_template.kernel_prompt_template:Rendered prompt: \n",
      "    Determine which participant takes the next turn in a conversation based on the the most recent participant.\n",
      "    State only the name of the participant to take the next turn.\n",
      "    No participant should take more than one turn in a row.\n",
      "\n",
      "    Choose only from these participants:\n",
      "        - Formulator\n",
      "        - Retriever\n",
      "        - Evaluator\n",
      "\n",
      "    Always follow these rules when selecting the next participant:\n",
      "    - Formulator starts first and formulates the query.\n",
      "    - After Formulator, it is Retriever's turn to retrieve the document.\n",
      "    - After Retriever, it is Evaluator's turn to evaluate the content.\n",
      "    - After Evaluator, the workflow may terminate if approved.\n",
      "\n",
      "    History:\n",
      "    [{'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}, {'role': 'assistant', 'content': 'site:gov OR site:edu policy relevant criteria', 'name': 'Formulator'}]\n",
      "    \n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '8c8be25c9f5b411a8bdc65a84271579b'}, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Determine which participant takes the next turn in a conversation based on the the most recent participant.\\n    State only the name of the participant to take the next turn.\\n    No participant should take more than one turn in a row.\\n\\n    Choose only from these participants:\\n        - Formulator\\n        - Retriever\\n        - Evaluator\\n\\n    Always follow these rules when selecting the next participant:\\n    - Formulator starts first and formulates the query.\\n    - After Formulator, it is Retriever's turn to retrieve the document.\\n    - After Retriever, it is Evaluator's turn to evaluate the content.\\n    - After Evaluator, the workflow may terminate if approved.\\n\\n    History:\\n    [{'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}, {'role': 'assistant', 'content': 'site:gov OR site:edu policy relevant criteria', 'name': 'Formulator'}]\"}], 'model': 'gpt-4o-standard', 'stream': False}}\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# assistant - Formulator: 'site:gov OR site:edu policy relevant criteria'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'332'), (b'Content-Type', b'application/json'), (b'apim-request-id', b'c9bb985f-c68c-4b06-aaa5-580e50845bb7'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-remaining-requests', b'147'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'1729d506-d95f-4075-89b5-64de44c393fe'), (b'x-content-type-options', b'nosniff'), (b'azureml-model-session', b'd097-20241115065003'), (b'x-ms-region', b'East US'), (b'x-envoy-upstream-service-time', b'157'), (b'x-ms-client-request-id', b'c9bb985f-c68c-4b06-aaa5-580e50845bb7'), (b'x-ratelimit-remaining-tokens', b'147583'), (b'Date', b'Mon, 16 Dec 2024 04:14:19 GMT')])\n",
      "INFO:httpx:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"200 OK\"\n",
      "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=1, prompt_tokens=198, total_tokens=199, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "INFO:semantic_kernel.functions.kernel_function:Function selection succeeded.\n",
      "DEBUG:semantic_kernel.functions.kernel_function:Function result: Retriever\n",
      "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.261354s\n",
      "INFO:semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy:Kernel Function Selection Strategy next method completed: , selection, result: [ChatMessageContent(inner_content=ChatCompletion(id='chatcmpl-Aewmp49cH1j71OtGofM4Rx4LK1myq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Retriever', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1734322459, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_04751d0b65', usage=CompletionUsage(completion_tokens=1, prompt_tokens=198, total_tokens=199, completion_tokens_details=None, prompt_tokens_details=None)), ai_model_id='gpt-4o-standard', metadata={'logprobs': None, 'id': 'chatcmpl-Aewmp49cH1j71OtGofM4Rx4LK1myq', 'created': 1734322459, 'system_fingerprint': 'fp_04751d0b65', 'usage': CompletionUsage(prompt_tokens=198, completion_tokens=1)}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Retriever', encoding=None)], encoding=None, finish_reason=<FinishReason.STOP: 'stop'>)]\n",
      "INFO:semantic_kernel.agents.group_chat.agent_chat:Invoking agent Retriever\n",
      "DEBUG:semantic_kernel.agents.chat_completion.chat_completion_agent:[ChatCompletionAgent] Invoking AzureChatCompletion.\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '8c8be25c9f5b411a8bdc65a84271579b'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\nYou are responsible for retrieving content from Azure AI Search.\\nUse the provided query to search the database and return the top document results.\\nPlease make sure to determine the retrieval strategy based on the query. Classify the query first and then retrieve the information.\\nIf there are no results, state 'No relevant content found.'\\n\", 'name': 'Retriever'}, {'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}, {'role': 'assistant', 'content': 'site:gov OR site:edu policy relevant criteria', 'name': 'Formulator'}], 'model': 'gpt-4o-standard', 'stream': False}}\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='aoai-ai-factory-eus-dev.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000021E4465D6F0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021E435599C0> server_hostname='aoai-ai-factory-eus-dev.openai.azure.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000021E4465E020>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'477'), (b'Content-Type', b'application/json'), (b'apim-request-id', b'b85f1599-a951-467a-83c2-cbe6c6499444'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-remaining-requests', b'146'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'e545cef8-58bc-4ff3-9419-cfda9ef97e4d'), (b'x-content-type-options', b'nosniff'), (b'azureml-model-session', b'd099-20241115090635'), (b'x-ms-region', b'East US'), (b'x-envoy-upstream-service-time', b'451'), (b'x-ms-client-request-id', b'b85f1599-a951-467a-83c2-cbe6c6499444'), (b'x-ratelimit-remaining-tokens', b'146828'), (b'Date', b'Mon, 16 Dec 2024 04:14:19 GMT')])\n",
      "INFO:httpx:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"200 OK\"\n",
      "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=29, prompt_tokens=107, total_tokens=136, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "INFO:semantic_kernel.agents.chat_completion.chat_completion_agent:[ChatCompletionAgent] Invoked AzureChatCompletion with message count: 3.\n",
      "INFO:semantic_kernel.agents.strategies.termination.termination_strategy:Evaluating termination criteria for 08baad57-a668-4620-8ba6-e0ab79c2efa7\n",
      "INFO:semantic_kernel.agents.strategies.termination.termination_strategy:Agent 08baad57-a668-4620-8ba6-e0ab79c2efa7 is out of scope\n",
      "INFO:semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy:Kernel Function Selection Strategy next method called, invoking function: , selection\n",
      "INFO:semantic_kernel.functions.kernel_function:Function selection invoking.\n",
      "DEBUG:semantic_kernel.functions.kernel_function:Function arguments: {'agents': 'Formulator,Retriever,Evaluator', 'history': [{'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}, {'role': 'assistant', 'content': 'site:gov OR site:edu policy relevant criteria', 'name': 'Formulator'}, {'role': 'assistant', 'content': 'Could you please provide the specific criteria or the topic that you are interested in? This will help me in retrieving the most relevant policy for you.', 'name': 'Retriever'}]}\n",
      "DEBUG:semantic_kernel.prompt_template.kernel_prompt_template:Rendering list of 3 blocks\n",
      "DEBUG:semantic_kernel.prompt_template.kernel_prompt_template:Rendered prompt: \n",
      "    Determine which participant takes the next turn in a conversation based on the the most recent participant.\n",
      "    State only the name of the participant to take the next turn.\n",
      "    No participant should take more than one turn in a row.\n",
      "\n",
      "    Choose only from these participants:\n",
      "        - Formulator\n",
      "        - Retriever\n",
      "        - Evaluator\n",
      "\n",
      "    Always follow these rules when selecting the next participant:\n",
      "    - Formulator starts first and formulates the query.\n",
      "    - After Formulator, it is Retriever's turn to retrieve the document.\n",
      "    - After Retriever, it is Evaluator's turn to evaluate the content.\n",
      "    - After Evaluator, the workflow may terminate if approved.\n",
      "\n",
      "    History:\n",
      "    [{'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}, {'role': 'assistant', 'content': 'site:gov OR site:edu policy relevant criteria', 'name': 'Formulator'}, {'role': 'assistant', 'content': 'Could you please provide the specific criteria or the topic that you are interested in? This will help me in retrieving the most relevant policy for you.', 'name': 'Retriever'}]\n",
      "    \n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '8c8be25c9f5b411a8bdc65a84271579b'}, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Determine which participant takes the next turn in a conversation based on the the most recent participant.\\n    State only the name of the participant to take the next turn.\\n    No participant should take more than one turn in a row.\\n\\n    Choose only from these participants:\\n        - Formulator\\n        - Retriever\\n        - Evaluator\\n\\n    Always follow these rules when selecting the next participant:\\n    - Formulator starts first and formulates the query.\\n    - After Formulator, it is Retriever's turn to retrieve the document.\\n    - After Retriever, it is Evaluator's turn to evaluate the content.\\n    - After Evaluator, the workflow may terminate if approved.\\n\\n    History:\\n    [{'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}, {'role': 'assistant', 'content': 'site:gov OR site:edu policy relevant criteria', 'name': 'Formulator'}, {'role': 'assistant', 'content': 'Could you please provide the specific criteria or the topic that you are interested in? This will help me in retrieving the most relevant policy for you.', 'name': 'Retriever'}]\"}], 'model': 'gpt-4o-standard', 'stream': False}}\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# assistant - Retriever: 'Could you please provide the specific criteria or the topic that you are interested in? This will help me in retrieving the most relevant policy for you.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'332'), (b'Content-Type', b'application/json'), (b'apim-request-id', b'59ca286d-8da3-40da-b309-183dd5b11d4b'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-remaining-requests', b'145'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'446f01f7-be0f-4a16-8765-f3fea671f9d5'), (b'x-content-type-options', b'nosniff'), (b'azureml-model-session', b'd100-20241115101253'), (b'x-ms-region', b'East US'), (b'x-envoy-upstream-service-time', b'149'), (b'x-ms-client-request-id', b'59ca286d-8da3-40da-b309-183dd5b11d4b'), (b'x-ratelimit-remaining-tokens', b'145912'), (b'Date', b'Mon, 16 Dec 2024 04:14:20 GMT')])\n",
      "INFO:httpx:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"200 OK\"\n",
      "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=1, prompt_tokens=243, total_tokens=244, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "INFO:semantic_kernel.functions.kernel_function:Function selection succeeded.\n",
      "DEBUG:semantic_kernel.functions.kernel_function:Function result: Evaluator\n",
      "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.247722s\n",
      "INFO:semantic_kernel.agents.strategies.selection.kernel_function_selection_strategy:Kernel Function Selection Strategy next method completed: , selection, result: [ChatMessageContent(inner_content=ChatCompletion(id='chatcmpl-AewmqiGydZ6GSH4BLDVrJU9kzAAVc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Evaluator', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1734322460, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_04751d0b65', usage=CompletionUsage(completion_tokens=1, prompt_tokens=243, total_tokens=244, completion_tokens_details=None, prompt_tokens_details=None)), ai_model_id='gpt-4o-standard', metadata={'logprobs': None, 'id': 'chatcmpl-AewmqiGydZ6GSH4BLDVrJU9kzAAVc', 'created': 1734322460, 'system_fingerprint': 'fp_04751d0b65', 'usage': CompletionUsage(prompt_tokens=243, completion_tokens=1)}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Evaluator', encoding=None)], encoding=None, finish_reason=<FinishReason.STOP: 'stop'>)]\n",
      "INFO:semantic_kernel.agents.group_chat.agent_chat:Invoking agent Evaluator\n",
      "DEBUG:semantic_kernel.agents.chat_completion.chat_completion_agent:[ChatCompletionAgent] Invoking AzureChatCompletion.\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '8c8be25c9f5b411a8bdc65a84271579b'}, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"\\nYou are responsible for evaluating if the retrieved content is accurate and matches the original clinical requirements.\\nIf the content is acceptable, respond 'Approved.'\\nIf the content is not accurate or does not solve the issue, suggest improvements without examples.\\n\", 'name': 'Evaluator'}, {'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}, {'role': 'assistant', 'content': 'site:gov OR site:edu policy relevant criteria', 'name': 'Formulator'}, {'role': 'assistant', 'content': 'Could you please provide the specific criteria or the topic that you are interested in? This will help me in retrieving the most relevant policy for you.', 'name': 'Retriever'}], 'model': 'gpt-4o-standard', 'stream': False}}\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='aoai-ai-factory-eus-dev.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000021E446A67D0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021E4355A5C0> server_hostname='aoai-ai-factory-eus-dev.openai.azure.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000021E446A3AF0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'332'), (b'Content-Type', b'application/json'), (b'apim-request-id', b'1c52c90e-cb72-4d7a-82d4-4325b52c2a81'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-remaining-requests', b'144'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'f7653581-74ce-4442-b8f8-dc1b3eaa7c1f'), (b'x-content-type-options', b'nosniff'), (b'azureml-model-session', b'd097-20241115065003'), (b'x-ms-region', b'East US'), (b'x-envoy-upstream-service-time', b'150'), (b'x-ms-client-request-id', b'1c52c90e-cb72-4d7a-82d4-4325b52c2a81'), (b'x-ratelimit-remaining-tokens', b'145136'), (b'Date', b'Mon, 16 Dec 2024 04:14:20 GMT')])\n",
      "INFO:httpx:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"200 OK\"\n",
      "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=2, prompt_tokens=125, total_tokens=127, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "INFO:semantic_kernel.agents.chat_completion.chat_completion_agent:[ChatCompletionAgent] Invoked AzureChatCompletion with message count: 4.\n",
      "INFO:semantic_kernel.agents.strategies.termination.termination_strategy:Evaluating termination criteria for d68ea3a9-fc97-4ce7-9d18-8291f0427460\n",
      "INFO:semantic_kernel.agents.strategies.termination.kernel_function_termination_strategy:should_agent_terminate, function invoking: `termination`\n",
      "INFO:semantic_kernel.functions.kernel_function:Function termination invoking.\n",
      "DEBUG:semantic_kernel.functions.kernel_function:Function arguments: {'_agent_': 'Evaluator', 'history': [{'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}, {'role': 'assistant', 'content': 'site:gov OR site:edu policy relevant criteria', 'name': 'Formulator'}, {'role': 'assistant', 'content': 'Could you please provide the specific criteria or the topic that you are interested in? This will help me in retrieving the most relevant policy for you.', 'name': 'Retriever'}, {'role': 'assistant', 'content': 'Approved.', 'name': 'Evaluator'}]}\n",
      "DEBUG:semantic_kernel.prompt_template.kernel_prompt_template:Rendering list of 3 blocks\n",
      "DEBUG:semantic_kernel.prompt_template.kernel_prompt_template:Rendered prompt: \n",
      "    Determine if the content evaluation has been approved. If so, respond 'yes.'\n",
      "    If not, state 'no.'\n",
      "\n",
      "    History:\n",
      "    [{'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}, {'role': 'assistant', 'content': 'site:gov OR site:edu policy relevant criteria', 'name': 'Formulator'}, {'role': 'assistant', 'content': 'Could you please provide the specific criteria or the topic that you are interested in? This will help me in retrieving the most relevant policy for you.', 'name': 'Retriever'}, {'role': 'assistant', 'content': 'Approved.', 'name': 'Evaluator'}]\n",
      "    \n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'api-key': '8c8be25c9f5b411a8bdc65a84271579b'}, 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"Determine if the content evaluation has been approved. If so, respond 'yes.'\\n    If not, state 'no.'\\n\\n    History:\\n    [{'role': 'user', 'content': 'I need the most relevant policy that matches my search criteria. '}, {'role': 'assistant', 'content': 'site:gov OR site:edu policy relevant criteria', 'name': 'Formulator'}, {'role': 'assistant', 'content': 'Could you please provide the specific criteria or the topic that you are interested in? This will help me in retrieving the most relevant policy for you.', 'name': 'Retriever'}, {'role': 'assistant', 'content': 'Approved.', 'name': 'Evaluator'}]\"}], 'model': 'gpt-4o-standard', 'stream': False}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='aoai-ai-factory-eus-dev.openai.azure.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000021E4460A770>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021E4355AC40> server_hostname='aoai-ai-factory-eus-dev.openai.azure.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000021E4460A140>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'326'), (b'Content-Type', b'application/json'), (b'apim-request-id', b'a29d3ee6-3a21-4b75-97ce-aa6594d7f432'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-remaining-requests', b'143'), (b'x-accel-buffering', b'no'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'67b3a9a4-d0d6-4100-868e-b4ad82d0bbe9'), (b'x-content-type-options', b'nosniff'), (b'azureml-model-session', b'd100-20241115101253'), (b'x-ms-region', b'East US'), (b'x-envoy-upstream-service-time', b'112'), (b'x-ms-client-request-id', b'a29d3ee6-3a21-4b75-97ce-aa6594d7f432'), (b'x-ratelimit-remaining-tokens', b'144345'), (b'Date', b'Mon, 16 Dec 2024 04:14:21 GMT')])\n",
      "INFO:httpx:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Request: POST https://aoai-ai-factory-eus-dev.openai.azure.com/openai/deployments/gpt-4o-standard/chat/completions?api-version=2023-05-15 \"200 OK\"\n",
      "INFO:semantic_kernel.connectors.ai.open_ai.services.open_ai_handler:OpenAI usage: CompletionUsage(completion_tokens=1, prompt_tokens=151, total_tokens=152, completion_tokens_details=None, prompt_tokens_details=None)\n",
      "INFO:semantic_kernel.functions.kernel_function:Function termination succeeded.\n",
      "DEBUG:semantic_kernel.functions.kernel_function:Function result: yes\n",
      "INFO:semantic_kernel.functions.kernel_function:Function completed. Duration: 0.327772s\n",
      "INFO:semantic_kernel.agents.strategies.termination.kernel_function_termination_strategy:should_agent_terminate, function `termination` invoked with result `[ChatMessageContent(inner_content=ChatCompletion(id='chatcmpl-Aewmr0OHrVolDZEj4GqeJGow3JO67', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='yes', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1734322461, model='gpt-4o-2024-05-13', object='chat.completion', service_tier=None, system_fingerprint='fp_04751d0b65', usage=CompletionUsage(completion_tokens=1, prompt_tokens=151, total_tokens=152, completion_tokens_details=None, prompt_tokens_details=None)), ai_model_id='gpt-4o-standard', metadata={'logprobs': None, 'id': 'chatcmpl-Aewmr0OHrVolDZEj4GqeJGow3JO67', 'created': 1734322461, 'system_fingerprint': 'fp_04751d0b65', 'usage': CompletionUsage(prompt_tokens=151, completion_tokens=1)}, content_type='message', role=<AuthorRole.ASSISTANT: 'assistant'>, name=None, items=[TextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='yes', encoding=None)], encoding=None, finish_reason=<FinishReason.STOP: 'stop'>)]`\n",
      "INFO:semantic_kernel.agents.strategies.termination.termination_strategy:Evaluated criteria for d68ea3a9-fc97-4ce7-9d18-8291f0427460, should terminate: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# assistant - Evaluator: 'Approved.'\n",
      "# Workflow Complete: True\n"
     ]
    }
   ],
   "source": [
    "selection_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"selection\",\n",
    "    prompt=f\"\"\"\n",
    "    Determine which participant takes the next turn in a conversation based on the the most recent participant.\n",
    "    State only the name of the participant to take the next turn.\n",
    "    No participant should take more than one turn in a row.\n",
    "\n",
    "    Choose only from these participants:\n",
    "        - {FORMULATOR_NAME}\n",
    "        - {RETRIEVER_NAME}\n",
    "        - {EVALUATOR_NAME}\n",
    "\n",
    "    Always follow these rules when selecting the next participant:\n",
    "    - {FORMULATOR_NAME} starts first and formulates the query.\n",
    "    - After {FORMULATOR_NAME}, it is {RETRIEVER_NAME}'s turn to retrieve the document.\n",
    "    - After {RETRIEVER_NAME}, it is {EVALUATOR_NAME}'s turn to evaluate the content.\n",
    "    - After {EVALUATOR_NAME}, the workflow may terminate if approved.\n",
    "\n",
    "    History:\n",
    "    {{{{$history}}}}\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "chat = AgentGroupChat(\n",
    "    agents=[agent_formulator, agent_retriever, agent_evaluator],\n",
    "    termination_strategy=KernelFunctionTerminationStrategy(\n",
    "        agents=[agent_evaluator],\n",
    "        function=termination_function,\n",
    "        kernel=_create_kernel_with_chat_completion(\"termination\"),\n",
    "        result_parser=lambda result: str(result.value[0]).lower() == \"yes\",\n",
    "        history_variable_name=\"history\",\n",
    "        maximum_iterations=10,\n",
    "    ),\n",
    "    selection_strategy=KernelFunctionSelectionStrategy(\n",
    "        function=selection_function,\n",
    "        kernel=_create_kernel_with_chat_completion(\"selection\"),\n",
    "        result_parser=lambda result: str(result.value[0]) if result.value is not None else FORMULATOR_NAME,\n",
    "        agent_variable_name=\"agents\",\n",
    "        history_variable_name=\"history\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "clinical_metadata = \"\"\"\n",
    "Patient with persistent lower back pain.\n",
    "Searching for policies related to chronic pain management and suitable treatments.\n",
    "\"\"\"\n",
    "\n",
    "clinical_metadata = \"I need the most relevant policy that matches my search criteria. \"\n",
    "\"Please classify the query and retrieve the best-matching policy using the most effective search strategy. \"\n",
    "\"Here is the clinical_metadata: Prior authorization for Adalimumab for Crohn's Disease and Anemia due to blood loss. \"\n",
    "\"Related terms: Crohn's Disease, regional enteritis, inflammatory bowel disease (IBD), chronic enteritis, ileitis, \"\n",
    "\"anemia secondary to blood loss, iron deficiency anemia, hemorrhagic anemia. \"\n",
    "\"Medication: Adalimumab, Humira, anti-TNF therapy, biologic therapy, TNF inhibitor. \"\n",
    "\"Dosage: 160 mg initial dose (four 40 mg injections), 80 mg two weeks later (two 40 mg injections), 40 mg every other week. \"\n",
    "\"Duration: 6 months. \"\n",
    "\"Rationale: Initiation of biologic therapy due to the severity of symptoms despite current treatment. \"\n",
    "\"Please evaluate this query using all available retrieval methods to determine the most effective classification and strategy. \"\n",
    "\"Once you have the classification, use it to select one of the following retrieval strategies: **keyword**, **semantic**, or **hybrid** search.\\n\\n\"\n",
    "\"Evaluate all the retrieved policies and calculate their confidence scores. Return a detailed JSON object as follows:\\n\"\n",
    "\"1. **List of Evaluated Policies**: Each policy includes its name, relevance score, and reasoning for its relevance.\\n\"\n",
    "\"2. **Confidence Levels**: Each policy is assigned a confidence score from 0 to 1.\\n\"\n",
    "\"3. **Final Policy Selection**: The system selects the policy with the highest confidence score.\\n\"\n",
    "\"4. **Return the JSON Object**: The response should be a JSON object with the following structure:\\n\"\n",
    "\"```json\\n\"\n",
    "\"{\\n\"\n",
    "\"  'evaluated_policies': [\\n\"\n",
    "\"    {\\n\"\n",
    "\"      'policy_name': '<name>',\\n\"\n",
    "\"      'confidence_score': <float>,\\n\"\n",
    "\"      'reasoning': '<explanation of why this policy was selected>'\\n\"\n",
    "\"    },\\n\"\n",
    "\"    ...\\n\"\n",
    "\"  ],\\n\"\n",
    "\"  'final_selected_policy': {\\n\"\n",
    "\"    'policy_name': '<name>',\\n\"\n",
    "\"    'confidence_score': <float>,\\n\"\n",
    "\"    'reasoning': '<why this policy was selected as the best option>'\\n\"\n",
    "\"  }\\n\"\n",
    "\"}\\n\"\n",
    "\n",
    "# Start the chat with Formulator using user input\n",
    "await chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=clinical_metadata))\n",
    "print(f\"# {AuthorRole.USER}: '{clinical_metadata}'\")\n",
    "\n",
    "# Iterate through the agent group chat workflow\n",
    "async for content in chat.invoke():\n",
    "    print(f\"# {content.role} - {content.name or '*'}: '{content.content}'\")\n",
    "\n",
    "print(f\"# Workflow Complete: {chat.is_complete}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Multi-Agent Orchestrator\n",
    "\n",
    "class MultiAgentOrchestrator:\n",
    "    \"\"\"Main Orchestrator to manage all agents and task execution.\"\"\"\n",
    "    def __init__(self, kernel: sk.Kernel):\n",
    "        self.kernel = kernel\n",
    "        self.agents = {}\n",
    "        self.planner = sk.Planning.SequentialPlanner(kernel)  # Orchestrates step-by-step task execution\n",
    "    \n",
    "    def register_agent(self, agent: Agent):\n",
    "        \"\"\"Add agent to the system.\"\"\"\n",
    "        self.agents[agent.name] = agent\n",
    "\n",
    "    async def execute_workflow(self, objective: str):\n",
    "        \"\"\"Execute workflow to achieve an objective.\"\"\"\n",
    "        print(\"Creating a plan for objective:\", objective)\n",
    "        plan = await self.planner.create_plan(objective)\n",
    "        print(\"Plan created. Executing steps.\")\n",
    "        results = await self.execute_plan(plan)\n",
    "        return results\n",
    "\n",
    "    async def execute_plan(self, plan):\n",
    "        \"\"\"Execute the step-by-step plan.\"\"\"\n",
    "        for step in plan.steps:\n",
    "            agent_name = step.target_agent\n",
    "            if agent_name in self.agents:\n",
    "                agent = self.agents[agent_name]\n",
    "                context = agent.context\n",
    "                context.update(step.variables)\n",
    "                result = await agent.kernel.execute(step.action, context)\n",
    "                print(f\"Result from {agent_name}: {result}\")\n",
    "        return result\n",
    "\n",
    "\n",
    "# Step 6: Register Agents with the Orchestrator\n",
    "\n",
    "orchestrator = MultiAgentOrchestrator(kernel=kernel)\n",
    "\n",
    "# Register all agents\n",
    "orchestrator.register_agent(retrieval_agent)\n",
    "orchestrator.register_agent(validation_agent)\n",
    "orchestrator.register_agent(query_rewrite_agent)\n",
    "\n",
    "\n",
    "# Step 7: Execute the Workflow\n",
    "\n",
    "async def main():\n",
    "    objective = \"Retrieve prior authorization policy for diabetes treatment and validate against the original document\"\n",
    "    print(\"Starting workflow for objective:\", objective)\n",
    "    final_result = await orchestrator.execute_workflow(objective)\n",
    "    print(f\"Final Result: {final_result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pa-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
