{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Prerequisites\n",
    "\n",
    "Ensure that your Azure Services are properly set up, your Conda environment is created, and your environment variables are configured as per the instructions in the [README.md](README.md) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install azure-search-documents==11.6.0b5\n",
    "# !pip install python-dotenv\n",
    "# !pip install azure-storage-blob\n",
    "# !pip install azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "load_dotenv(override=True) # take environment variables from .env."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Env Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Azure Search\n",
    "endpoint = os.environ[\"AZURE_AI_SEARCH_SERVICE_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.getenv(\"AZURE_AI_SEARCH_ADMIN_KEY\")) if os.getenv(\"AZURE_AI_SEARCH_ADMIN_KEY\") else DefaultAzureCredential()\n",
    "index_name = os.getenv(\"AZURE_AI_SEARCH_INDEX_NAME\", \"ai-policies-index\")\n",
    "\n",
    "#blob storage\n",
    "blob_connection_string= os.environ[\"AZURE_STORAGE_CONNECTION_STRING\"]\n",
    "search_blob_connection_string= os.getenv(\"SEARCH_BLOB_DATASOURCE_CONNECTION_STRING\", blob_connection_string)\n",
    "blob_container_name = os.getenv(\"BLOB_CONTAINER_NAME\", \"pre-auth-policies\")\n",
    "\n",
    "#Azure OpenAI\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_model_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\", \"text-embedding-3-large\")\n",
    "azure_openai_model_dimensions = int(os.getenv(\"AZURE_OPENAI_EMBEDDING_DIMENSIONS\", 3072))\n",
    "\n",
    "# This field is only necessary if you want to use OCR to scan PDFs in the data source\n",
    "azure_ai_services_key = os.getenv(\"AZURE_AI_SERVICES_KEY\", \"\")\n",
    "\n",
    "use_ocr = len(azure_ai_services_key) > 0\n",
    "# OCR must be used to add page numbers\n",
    "add_page_numbers = use_ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Policies to Blob Storage\n",
    "\n",
    "In this section, we will upload policy documents to Azure Blob Storage. This process involves connecting to the Azure Blob Storage account, creating a container if it doesn't already exist, and uploading the policy documents from a specified local directory to the blob container. \n",
    "\n",
    "### Steps:\n",
    "1. **Initialize Azure Blob Storage Client**: Connect to the Azure Blob Storage account using the connection string and set up the container client.\n",
    "2. **Create Container (if not exists)**: Ensure the specified container exists in the Blob Storage. If it doesn't, create it.\n",
    "3. **Upload Policy Documents**: Iterate through the local directory containing the policy documents and upload each document to the Blob Storage container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 19:35:25,489 - micro - MainProcess - INFO     Container 'pre-auth-policies' already exists. (blob_helper.py:_create_container_if_not_exists:73)\n"
     ]
    }
   ],
   "source": [
    "from src.storage.blob_helper import AzureBlobManager\n",
    "\n",
    "uploader = AzureBlobManager(\n",
    "    storage_account_name = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\"),\n",
    "    container_name = blob_container_name,\n",
    "    account_key = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_PATH = \"C:\\\\Users\\\\pablosal\\\\Desktop\\\\gbb-ai-hls-factory-prior-auth\\\\utils\\\\data\\\\cases\\\\policies\\\\\"\n",
    "REMOTE_PATH = \"policies_ocr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 19:37:36,062 - micro - MainProcess - INFO     File 'C:\\Users\\pablosal\\Desktop\\gbb-ai-hls-factory-prior-auth\\utils\\data\\cases\\policies\\001_inflammatory_Conditions.pdf' uploaded to blob 'policies_ocr/001_inflammatory_Conditions.pdf' successfully. (blob_helper.py:_upload_files_with_extension:207)\n",
      "2024-10-29 19:37:36,156 - micro - MainProcess - INFO     File 'C:\\Users\\pablosal\\Desktop\\gbb-ai-hls-factory-prior-auth\\utils\\data\\cases\\policies\\002_seizures_Conditions.pdf' uploaded to blob 'policies_ocr/002_seizures_Conditions.pdf' successfully. (blob_helper.py:_upload_files_with_extension:207)\n"
     ]
    }
   ],
   "source": [
    "uploader.upload_file(local_file_path=LOCAL_PATH, \n",
    "                     remote_blob_path=REMOTE_PATH,\n",
    "                     overwrite=True,\n",
    "                     extension=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up a Blob Data Source Connector in Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source 'ai-policies-index-blob' created or updated\n"
     ]
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerDataContainer,\n",
    "    NativeBlobSoftDeleteDeletionDetectionPolicy\n",
    ")\n",
    "\n",
    "# Initialize the SearchIndexerClient\n",
    "indexer_client = SearchIndexerClient(endpoint, credential)\n",
    "\n",
    "# Create a data container for your blob storage\n",
    "container = SearchIndexerDataContainer(name=blob_container_name)\n",
    "\n",
    "# Notes:\n",
    "# - data_change_detection_policy is not applicable for Blob Storage. The indexer automatically detects changes in blobs based on their LastModified timestamps.\n",
    "# - Include data_deletion_detection_policy if needed. Use it to detect deletions, but remember to enable soft delete on your storage account.\n",
    "\n",
    "# Create a data source connection without data_change_detection_policy\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=f\"{index_name}-blob\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=search_blob_connection_string,\n",
    "    container=container,\n",
    "    data_deletion_detection_policy=NativeBlobSoftDeleteDeletionDetectionPolicy()\n",
    ")\n",
    "\n",
    "# Create or update the data source connection\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Search Index\n",
    "\n",
    "A search index is where both vector and non-vector content is stored. This index enables efficient searching and retrieval of documents, allowing for advanced search capabilities and quick access to relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    AzureOpenAIVectorizer,\n",
    "    SemanticConfiguration,\n",
    "    SemanticSearch,\n",
    "    SemanticSearch,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SearchIndex,\n",
    "    HnswParameters,\n",
    "    SimpleField,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataSourceType,\n",
    "    NativeBlobSoftDeleteDeletionDetectionPolicy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search index  \n",
    "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fields\n",
    "fields = [\n",
    "    SearchField(\n",
    "        name=\"parent_id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        sortable=True,\n",
    "        filterable=True,\n",
    "        facetable=True\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"parent_path\",\n",
    "        type=SearchFieldDataType.String,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"chunk_id\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "        sortable=True,\n",
    "        filterable=True,\n",
    "        facetable=True,\n",
    "        analyzer_name=\"keyword\"\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"chunk\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "        sortable=False,\n",
    "        filterable=False,\n",
    "        facetable=False,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        vector_search_dimensions=azure_openai_model_dimensions,\n",
    "        vector_search_profile_name=\"myHnswProfile\"\n",
    "    )\n",
    "]\n",
    "\n",
    "if add_page_numbers:\n",
    "    fields.append(\n",
    "        SearchField(name=\"page_number\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=False)\n",
    "    )\n",
    "\n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\",\n",
    "                                   parameters=HnswParameters(\n",
    "                                        m=4,\n",
    "                                        ef_construction=400,\n",
    "                                        ef_search=500,\n",
    "                                   )),\n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "        )\n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "            parameters=AzureOpenAIVectorizerParameters(  \n",
    "                resource_url=azure_openai_endpoint,  \n",
    "                deployment_name=azure_openai_embedding_deployment,\n",
    "                model_name=azure_openai_model_name,\n",
    "                api_key=azure_openai_key,\n",
    "            ),\n",
    "        ),  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "semantic_config = SemanticConfiguration(  \n",
    "    name=\"my-semantic-config\",  \n",
    "    prioritized_fields=SemanticPrioritizedFields(  \n",
    "        content_fields=[SemanticField(field_name=\"chunk\")]  \n",
    "    ),  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'ai-policies-index' created or updated successfully.\n"
     ]
    }
   ],
   "source": [
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=fields,\n",
    "    vector_search=vector_search,\n",
    "    semantic_search=semantic_search\n",
    ")\n",
    "\n",
    "# Create or update the index\n",
    "index_result = index_client.create_or_update_index(index)\n",
    "print(f\"Index '{index_result.name}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Skillset for Integrated Vectorization\n",
    "\n",
    "A skillset in Azure AI Search defines a collection of skills that are applied to your data during indexing. These skills can include text splitting for data chunking, vectorization using Azure OpenAI embeddings, and more. By configuring a skillset, you can enhance your search index with advanced capabilities, making it more efficient and powerful.\n",
    "\n",
    "### Key Components:\n",
    "1. **Text Split Skill**: This skill chunks your data into manageable pieces, improving the granularity and relevance of search results.\n",
    "2. **Azure OpenAI Embedding Skill**: This skill integrates with Azure OpenAI to generate embeddings for your data, enhancing vector search capabilities.\n",
    "3. **Indexer Projection**: Specifies secondary indexes used for chunked data, ensuring that the processed data is correctly indexed and searchable.\n",
    "\n",
    "By setting up a skillset, you can leverage these advanced features to create a more robust and efficient search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    OcrSkill,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    SearchIndexerSkillset,\n",
    "    CognitiveServicesAccountKey\n",
    ")\n",
    "\n",
    "# Create a skillset  \n",
    "skillset_name = f\"{index_name}-skillset\"\n",
    "\n",
    "def create_ocr_skillset():\n",
    "    ocr_skill = OcrSkill(\n",
    "        description=\"OCR skill to scan PDFs and other images with text\",\n",
    "        context=\"/document/normalized_images/*\",\n",
    "        line_ending=\"Space\",\n",
    "        default_language_code=\"en\",\n",
    "        should_detect_orientation=True,\n",
    "        inputs=[\n",
    "            InputFieldMappingEntry(name=\"image\", source=\"/document/normalized_images/*\")\n",
    "        ],\n",
    "        outputs=[\n",
    "            OutputFieldMappingEntry(name=\"text\", target_name=\"text\"),\n",
    "            OutputFieldMappingEntry(name=\"layoutText\", target_name=\"layoutText\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    split_skill = SplitSkill(  \n",
    "        description=\"Split skill to chunk documents\",  \n",
    "        text_split_mode=\"pages\",  \n",
    "        context=\"/document/normalized_images/*\",  \n",
    "        maximum_page_length=3000,  \n",
    "        page_overlap_length=500,  \n",
    "        inputs=[  \n",
    "            InputFieldMappingEntry(name=\"text\", source=\"/document/normalized_images/*/text\"),  \n",
    "        ],  \n",
    "        outputs=[  \n",
    "            OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "        description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "        context=\"/document/normalized_images/*/pages/*\",  \n",
    "        resource_url=azure_openai_endpoint,  \n",
    "        deployment_name=azure_openai_embedding_deployment,  \n",
    "        model_name=azure_openai_model_name,\n",
    "        dimensions=azure_openai_model_dimensions,\n",
    "        api_key=azure_openai_key,  \n",
    "        inputs=[  \n",
    "            InputFieldMappingEntry(name=\"text\", source=\"/document/normalized_images/*/pages/*\"),  \n",
    "        ],  \n",
    "        outputs=[\n",
    "            OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")  \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    index_projections = SearchIndexerIndexProjection(  \n",
    "        selectors=[  \n",
    "            SearchIndexerIndexProjectionSelector(  \n",
    "                target_index_name=index_name,  \n",
    "                parent_key_field_name=\"parent_id\",  \n",
    "                source_context=\"/document/normalized_images/*/pages/*\",  \n",
    "                mappings=[\n",
    "                    InputFieldMappingEntry(name=\"chunk\", source=\"/document/normalized_images/*/pages/*\"),  \n",
    "                    InputFieldMappingEntry(name=\"vector\", source=\"/document/normalized_images/*/pages/*/vector\"),\n",
    "                    InputFieldMappingEntry(name=\"parent_path\", source=\"/document/metadata_storage_path\"),\n",
    "                    InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),\n",
    "                    InputFieldMappingEntry(name=\"page_number\", source=\"/document/normalized_images/*/pageNumber\")\n",
    "                ]\n",
    "            )\n",
    "        ],  \n",
    "        parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "            projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "        )  \n",
    "    )\n",
    "\n",
    "    cognitive_services_account = CognitiveServicesAccountKey(key=azure_ai_services_key) if use_ocr else None\n",
    "\n",
    "    skills = [ocr_skill, split_skill, embedding_skill]\n",
    "\n",
    "    return SearchIndexerSkillset(  \n",
    "        name=skillset_name,  \n",
    "        description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "        skills=skills,  \n",
    "        index_projection=index_projections,\n",
    "        cognitive_services_account=cognitive_services_account\n",
    "    )\n",
    "\n",
    "def create_skillset():\n",
    "    split_skill = SplitSkill(  \n",
    "        description=\"Split skill to chunk documents\",  \n",
    "        text_split_mode=\"pages\",  \n",
    "        context=\"/document\",  \n",
    "        maximum_page_length=2000,  \n",
    "        page_overlap_length=500,  \n",
    "        inputs=[  \n",
    "            InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
    "        ],  \n",
    "        outputs=[  \n",
    "            OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "        description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "        context=\"/document/pages/*\",  \n",
    "        resource_url=azure_openai_endpoint,  \n",
    "        deployment_name=azure_openai_embedding_deployment,  \n",
    "        model_name=azure_openai_model_name,\n",
    "        dimensions=azure_openai_model_dimensions,\n",
    "        api_key=azure_openai_key,  \n",
    "        inputs=[  \n",
    "            InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "        ],  \n",
    "        outputs=[\n",
    "            OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")  \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    index_projections = SearchIndexerIndexProjection(  \n",
    "        selectors=[  \n",
    "            SearchIndexerIndexProjectionSelector(  \n",
    "                target_index_name=index_name,  \n",
    "                parent_key_field_name=\"parent_id\",  \n",
    "                source_context=\"/document/pages/*\",  \n",
    "                mappings=[\n",
    "                    InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),  \n",
    "                    InputFieldMappingEntry(name=\"vector\", source=\"/document/pages/*/vector\"),\n",
    "                    InputFieldMappingEntry(name=\"parent_path\", source=\"/document/metadata_storage_path\"),\n",
    "                    InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),\n",
    "                ]\n",
    "            )\n",
    "        ],  \n",
    "        parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "            projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "        )  \n",
    "    )\n",
    "\n",
    "    cognitive_services_account = CognitiveServicesAccountKey(key=azure_ai_services_key) if use_ocr else None\n",
    "\n",
    "    skills = [split_skill, embedding_skill]\n",
    "\n",
    "    return SearchIndexerSkillset(  \n",
    "        name=skillset_name,  \n",
    "        description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "        skills=skills,  \n",
    "        index_projection=index_projections,\n",
    "        cognitive_services_account=cognitive_services_account\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai-policies-index-skillset created\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "try:\n",
    "    skillset = create_ocr_skillset()\n",
    "    client = SearchIndexerClient(endpoint, credential)\n",
    "    client.create_or_update_skillset(skillset)\n",
    "    print(f\"{skillset.name} created\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create skillset: {e.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import IndexingParameters\n",
    "\n",
    "# Configure indexing parameters to include blob metadata\n",
    "indexing_parameters = IndexingParameters(\n",
    "    configuration={\n",
    "        \"parsingMode\": \"default\",\n",
    "        \"indexStorageMetadata\": True\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ai-policies-index-indexer is created and running. If queries return no results, please wait a bit and try again.\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndexer,\n",
    "    IndexingParameters,\n",
    "    IndexingParametersConfiguration,\n",
    "    BlobIndexerImageAction\n",
    ")\n",
    "\n",
    "# Create an indexer  \n",
    "indexer_name = f\"{index_name}-indexer\"  \n",
    "\n",
    "indexer_parameters = None\n",
    "if use_ocr:\n",
    "    indexer_parameters = IndexingParameters(\n",
    "        configuration=IndexingParametersConfiguration(\n",
    "            image_action=BlobIndexerImageAction.GENERATE_NORMALIZED_IMAGE_PER_PAGE,\n",
    "            query_timeout=None))\n",
    "\n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,\n",
    "    parameters=indexer_parameters\n",
    ")  \n",
    "\n",
    "indexer_client = SearchIndexerClient(endpoint, credential)  \n",
    "indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "  \n",
    "# Run the indexer  \n",
    "indexer_client.run_indexer(indexer_name)  \n",
    "print(f' {indexer_name} is created and running. If queries return no results, please wait a bit and try again.')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client = SearchClient(\n",
    "    endpoint=os.environ[\"AZURE_AI_SEARCH_SERVICE_ENDPOINT\"],\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(os.environ[\"AZURE_AI_SEARCH_ADMIN_KEY\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_QUERY = \"policy about Neurological Disorders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query = VectorizableTextQuery(text=SEARCH_QUERY, k_nearest_neighbors=5, fields=\"vector\", exhaustive=True, weight=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "ID: 3ac582c1bab4_aHR0cHM6Ly9zdG9yYWdlYWVhc3R1c2ZhY3RvcnkuYmxvYi5jb3JlLndpbmRvd3MubmV0L3ByZS1hdXRoLXBvbGljaWVzL3BvbGljaWVzX29jci8wMDJfc2VpenVyZXNfQ29uZGl0aW9ucy5wZGY1_normalized_images_3_pages_0\n",
      "Reranker Score: 2.5161070823669434\n",
      "Source_doc_path: https://storageaeastusfactory.blob.core.windows.net/pre-auth-policies/policies_ocr/002_seizures_Conditions.pdf\n",
      "Content: 1. Dravet Syndrome. Approve if the patient meets ONE of the following (A or B): A) Initial Therapy. ...\n",
      "Caption: 1. Dravet Syndrome. Approve for 1 year if the patient is responding to therapy (e.g ., reduced seizure severity, frequency, and/or duration) as determined by the prescriber. 2.<em> Lennox-Gastaut Syndrome.</em> Approve if the patient meets ONE of the following (A or B): A) Initial Therapy. 3.<em> Tuberous Sclerosis Complex.</em> Approve if the patient meets ONE of.\n",
      "========================================\n",
      "========================================\n",
      "ID: 3ac582c1bab4_aHR0cHM6Ly9zdG9yYWdlYWVhc3R1c2ZhY3RvcnkuYmxvYi5jb3JlLndpbmRvd3MubmV0L3ByZS1hdXRoLXBvbGljaWVzL3BvbGljaWVzX29jci8wMDJfc2VpenVyZXNfQ29uZGl0aW9ucy5wZGY1_normalized_images_1_pages_1\n",
      "Reranker Score: 2.4803056716918945\n",
      "Source_doc_path: https://storageaeastusfactory.blob.core.windows.net/pre-auth-policies/policies_ocr/002_seizures_Conditions.pdf\n",
      "Content: In a cohort of 132 patients (72 children, 60 adults) with treatment-resistant epilepsy, bi-weekly se...\n",
      "Caption: <em>...gnosis of Lennox-Gastaut syndrome or Dravet syI</em>n a separate cohort of<em> patients with CDKL5 deficiency disorder and Aicardi, Doose, and Dup15q syndromes </em>(n = 46), the<em> percent change in median convulsive seizure frequency </em>decreased from baseline to Week 12 by 51.4% and by 59.1% at Week 48.16 There was a significant difference between the percent.\n",
      "========================================\n",
      "========================================\n",
      "ID: 3ac582c1bab4_aHR0cHM6Ly9zdG9yYWdlYWVhc3R1c2ZhY3RvcnkuYmxvYi5jb3JlLndpbmRvd3MubmV0L3ByZS1hdXRoLXBvbGljaWVzL3BvbGljaWVzX29jci8wMDJfc2VpenVyZXNfQ29uZGl0aW9ucy5wZGY1_normalized_images_2_pages_0\n",
      "Reranker Score: 2.3232758045196533\n",
      "Source_doc_path: https://storageaeastusfactory.blob.core.windows.net/pre-auth-policies/policies_ocr/002_seizures_Conditions.pdf\n",
      "Content: Guidelines/Recommendations Dravet Syndrome At this time, there are three drugs approved for the trea...\n",
      "Caption: Guidelines/Recommendations Dravet Syndrome At this time, there are three drugs approved for the<em> treatment of seizures </em>associated with<em> Dravet </em>syndrome: Epidiolex, DiacomitÂ® (stiripentol capsules, powder for oral suspension), and FinteplaÂ® (fenfluramine oral solution).1,11,17 An expert panel considers valproic acid and clobazam to be the first-line.\n",
      "========================================\n",
      "========================================\n",
      "ID: 3ac582c1bab4_aHR0cHM6Ly9zdG9yYWdlYWVhc3R1c2ZhY3RvcnkuYmxvYi5jb3JlLndpbmRvd3MubmV0L3ByZS1hdXRoLXBvbGljaWVzL3BvbGljaWVzX29jci8wMDJfc2VpenVyZXNfQ29uZGl0aW9ucy5wZGY1_normalized_images_4_pages_1\n",
      "Reranker Score: 2.2418365478515625\n",
      "Source_doc_path: https://storageaeastusfactory.blob.core.windows.net/pre-auth-policies/policies_ocr/002_seizures_Conditions.pdf\n",
      "Content: AP, Ng YT. Treatment-resistant Lennox-Gastaut syndrome: therapeutic trends, challenges, and future d...\n",
      "Caption: Treatment-resistant Lennox-Gastaut syndrome: therapeuti... National Organization for Rare Diseases (NORD) - Lennox-Gastaut syndrome. National Institutes of Neurological Disorders and Stroke. Tuberous Sclerosis Fact Sheet. Last updated: November 28, 2023. Available at: https://www.ninds.nih.gov/health-.\n",
      "========================================\n",
      "========================================\n",
      "ID: 3ac582c1bab4_aHR0cHM6Ly9zdG9yYWdlYWVhc3R1c2ZhY3RvcnkuYmxvYi5jb3JlLndpbmRvd3MubmV0L3ByZS1hdXRoLXBvbGljaWVzL3BvbGljaWVzX29jci8wMDJfc2VpenVyZXNfQ29uZGl0aW9ucy5wZGY1_normalized_images_0_pages_1\n",
      "Reranker Score: 2.2404186725616455\n",
      "Source_doc_path: https://storageaeastusfactory.blob.core.windows.net/pre-auth-policies/policies_ocr/002_seizures_Conditions.pdf\n",
      "Content: Dravet syndrome is a rare genetic epileptic encephalopathy marked with frequent and/or prolonged sei...\n",
      "Caption: Affected individuals can develop many<em> seizure </em>types: myoclonic, tonic... The goals of treatment are<em> cessation of prolonged convulsions, </em>reduction in overall seizure frequency, and minimization of treatment side effects. 4,5 Lennox-Gastaut syndrome, a severe epileptic and<em> developmental encephalopathy, </em>is associated with a high rate of morbidity and.\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.models import QueryType, QueryCaptionType, QueryAnswerType\n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=SEARCH_QUERY,  \n",
    "    vector_queries=[vector_query],\n",
    "    #select=[\"content\", \"id\"],\n",
    "    #filters = \n",
    "    query_type=QueryType.SEMANTIC, semantic_configuration_name='my-semantic-config', query_caption=QueryCaptionType.EXTRACTIVE, query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=5\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"ID: {result['chunk_id']}\")\n",
    "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
    "    print(f\"Source_doc_path: {result['parent_path']}\")\n",
    "    content = result['chunk'][:100] + '...' if len(result['chunk']) > 100 else result['chunk']\n",
    "    print(f\"Content: {content}\")\n",
    "\n",
    "    captions = result.get(\"@search.captions\", [])\n",
    "    if captions:\n",
    "        caption = captions[0]\n",
    "        if caption.highlights:\n",
    "            print(f\"Caption: {caption.highlights}\")\n",
    "        else:\n",
    "            print(f\"Caption: {caption.text}\")\n",
    "    print(\"=\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pa-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
